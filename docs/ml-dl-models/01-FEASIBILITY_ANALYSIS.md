# ML/DL λ¨λΈ ν†µν•© κ°€λ¥μ„± λ¶„μ„

## π“‹ λ©μ°¨

1. [ν„μ¬ μΈν”„λΌ μƒνƒ](#ν„μ¬-μΈν”„λΌ-μƒνƒ)
2. [XGBoost κ°€λ¥μ„± ν‰κ°€](#xgboost-κ°€λ¥μ„±-ν‰κ°€)
3. [LightGBM κ°€λ¥μ„± ν‰κ°€](#lightgbm-κ°€λ¥μ„±-ν‰κ°€)
4. [TensorFlow/Keras κ°€λ¥μ„± ν‰κ°€](#tensorflowkeras-κ°€λ¥μ„±-ν‰κ°€)
5. [PyTorch κ°€λ¥μ„± ν‰κ°€](#pytorch-κ°€λ¥μ„±-ν‰κ°€)
6. [μΈν”„λΌ μ”κµ¬μ‚¬ν•­](#μΈν”„λΌ-μ”κµ¬μ‚¬ν•­)
7. [μ μ•½μ‚¬ν•­ λ° μ„ν—μ”μ†](#μ μ•½μ‚¬ν•­-λ°-μ„ν—μ”μ†)
8. [κ²°λ΅ ](#κ²°λ΅ )

---

## ν„μ¬ μΈν”„λΌ μƒνƒ

### κΈ°μ΅΄ ML μ¤νƒ

| μ»΄ν¬λ„νΈ | ν„μ¬ μƒνƒ | λ²„μ „ |
|---------|----------|------|
| scikit-learn | β… μ„¤μΉλ¨ | 1.3.2 |
| MLflow | β… μ„¤μΉλ¨ | 2.9.2 |
| Airflow | β… μ‹¤ν–‰ μ¤‘ | 2.8.0 |
| XGBoost | β λ―Έμ„¤μΉ | - |
| LightGBM | β λ―Έμ„¤μΉ | - |
| TensorFlow | β λ―Έμ„¤μΉ | - |
| PyTorch | β λ―Έμ„¤μΉ | - |

### μ‹¤ν–‰ ν™κ²½

- **Airflow Worker**: Python task μ‹¤ν–‰ κ°€λ¥ (CeleryExecutor)
- **Jupyter Lab**: spark-iceberg μ»¨ν…μ΄λ„ (ν¬νΈ 8888)
- **MLflow**: μ‹¤ν— μ¶”μ  λ° λ¨λΈ λ μ§€μ¤νΈλ¦¬ (ν¬νΈ 5000)
- **S3 Storage**: SeaweedFS (λ¨λΈ μ•„ν‹°ν©νΈ μ €μ¥)
- **Data Lake**: Iceberg + Trino

### κΈ°μ΅΄ ML νμ΄ν”„λΌμΈ

μ°Έμ΅°: `/home/i/work/ai/lakehouse-tick/dags/ml_pipeline_dag.py`

- **λ¨λΈ**: RandomForestClassifier (scikit-learn)
- **νμ΄ν”„λΌμΈ**: RAW β†’ Bronze β†’ Silver β†’ Gold β†’ Features β†’ Train β†’ Registry
- **MLflow ν†µν•©**: μ™„λ£ (νλΌλ―Έν„°, λ©”νΈλ¦­, λ¨λΈ λ΅κΉ…)
- **μ‹¤ν–‰ μ£ΌκΈ°**: μΌμΌ μ¤μΌ€μ¤„

---

## XGBoost κ°€λ¥μ„± ν‰κ°€

### β… κ°€λ¥ μ—¬λ¶€: **κ°€λ¥**

### ν•„μ” μ‘μ—…

1. **λΌμ΄λΈλ¬λ¦¬ μ¶”κ°€**
   - `requirements-airflow.txt`μ— `xgboost>=2.0.3` μ¶”κ°€

2. **λ¦¬μ†μ¤ μ”κµ¬μ‚¬ν•­**
   - CPU: μµμ† 2 cores (ν„μ¬ Airflow worker: 2 CPU) β…
   - Memory: μµμ† 2GB (ν„μ¬ Airflow worker: 2GB) β…
   - **κ²°λ΅ **: μ¶”κ°€ λ¦¬μ†μ¤ λ¶ν•„μ”

3. **MLflow ν†µν•©**
   - MLflowλ” XGBoost autologging μ§€μ›
   - `mlflow.xgboost.autolog()` μ‚¬μ© κ°€λ¥

4. **λ°μ΄ν„° νμ΄ν”„λΌμΈ**
   - κΈ°μ΅΄ Iceberg ν…μ΄λΈ” ν™μ© κ°€λ¥
   - Trino μΏΌλ¦¬λ΅ feature μ¶”μ¶

### μ½”λ“ μμ 

```python
import xgboost as xgb
import mlflow
import mlflow.xgboost

mlflow.xgboost.autolog()

with mlflow.start_run():
    dtrain = xgb.DMatrix(X_train, label=y_train)
    params = {
        'max_depth': 6,
        'eta': 0.3,
        'objective': 'binary:logistic',
        'eval_metric': 'logloss'
    }
    model = xgb.train(params, dtrain, num_boost_round=100)
```

### μμƒ μ„±λ¥

- **ν•™μµ μ†λ„**: scikit-learn RandomForest λ€λΉ„ 2-3λ°° λΉ λ¦„
- **λ©”λ¨λ¦¬**: μ μ‚¬ λλ” μ•½κ°„ μ μ
- **μ •ν™•λ„**: μΌλ°μ μΌλ΅ λ” λ†’μ

---

## LightGBM κ°€λ¥μ„± ν‰κ°€

### β… κ°€λ¥ μ—¬λ¶€: **κ°€λ¥**

### ν•„μ” μ‘μ—…

1. **λΌμ΄λΈλ¬λ¦¬ μ¶”κ°€**
   - `requirements-airflow.txt`μ— `lightgbm>=4.1.0` μ¶”κ°€

2. **λ¦¬μ†μ¤ μ”κµ¬μ‚¬ν•­**
   - CPU: μµμ† 2 cores β…
   - Memory: μµμ† 2GB β…
   - **κ²°λ΅ **: μ¶”κ°€ λ¦¬μ†μ¤ λ¶ν•„μ”

3. **MLflow ν†µν•©**
   - MLflowλ” LightGBM autologging μ§€μ›
   - `mlflow.lightgbm.autolog()` μ‚¬μ© κ°€λ¥

4. **νΉμ§•**
   - XGBoostλ³΄λ‹¤ μΌλ°μ μΌλ΅ λ” λΉ λ¦„
   - λ©”λ¨λ¦¬ ν¨μ¨μ 
   - λ²”μ£Όν• ν”Όμ² native μ§€μ›

### μ½”λ“ μμ 

```python
import lightgbm as lgb
import mlflow
import mlflow.lightgbm

mlflow.lightgbm.autolog()

with mlflow.start_run():
    dtrain = lgb.Dataset(X_train, label=y_train)
    params = {
        'num_leaves': 31,
        'learning_rate': 0.05,
        'objective': 'binary'
    }
    model = lgb.train(params, dtrain, num_boost_round=100)
```

### μμƒ μ„±λ¥

- **ν•™μµ μ†λ„**: XGBoost λ€λΉ„ 1.5-2λ°° λΉ λ¦„
- **λ©”λ¨λ¦¬**: XGBoost λ€λΉ„ μ•½κ°„ μ μ
- **μ •ν™•λ„**: μ μ‚¬ν•κ±°λ‚ μ•½κ°„ λ” λ†’μ„ μ μμ

---

## TensorFlow/Keras κ°€λ¥μ„± ν‰κ°€

### β… κ°€λ¥ μ—¬λ¶€: **κ°€λ¥**

### ν•„μ” μ‘μ—…

1. **λΌμ΄λΈλ¬λ¦¬ μ¶”κ°€**
   ```
   tensorflow>=2.15.0,<2.16.0
   keras>=3.0.0
   ```

2. **λ¦¬μ†μ¤ μ”κµ¬μ‚¬ν•­**

   **MNIST MLP**:
   - CPU: 2-4 cores (ν„μ¬: 2 CPU - ν•™μµ κ°€λ¥ν•λ‚ λλ¦΄ μ μμ)
   - Memory: 4GB (ν„μ¬: 2GB - **λ©”λ¨λ¦¬ μ¦κ°€ ν•„μ”**)
   - ν•™μµ μ‹κ°„: CPU κΈ°μ¤€ 5-10λ¶„

   **MNIST CNN**:
   - CPU: 4+ cores (ν„μ¬: 2 CPU - **μ¦κ°€ κ¶μ¥**)
   - Memory: 4-6GB (ν„μ¬: 2GB - **λ©”λ¨λ¦¬ μ¦κ°€ ν•„μ”**)
   - ν•™μµ μ‹κ°„: CPU κΈ°μ¤€ 20-30λ¶„

3. **Docker μ„¤μ • λ³€κ²½ ν•„μ”**
   ```yaml
   airflow-worker:
     deploy:
       resources:
         limits:
           cpus: '4'
           memory: 6G
         reservations:
           cpus: '2'
           memory: 4G
   ```

4. **MLflow ν†µν•©**
   - MLflowλ” TensorFlow/Keras autologging μ§€μ›
   - `mlflow.tensorflow.autolog()` μ‚¬μ© κ°€λ¥

5. **MNIST λ°μ΄ν„°μ…‹**
   - `tensorflow.keras.datasets.mnist` μ‚¬μ©
   - μλ™ λ‹¤μ΄λ΅λ“ (μ•½ 11MB)

### λ¨λΈ μ•„ν‚¤ν…μ²

**MNIST MLP**:
```python
from tensorflow import keras

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(10, activation='softmax')
])
# νλΌλ―Έν„° μ: ~100K
```

**MNIST CNN**:
```python
model = keras.Sequential([
    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    keras.layers.MaxPooling2D((2, 2)),
    keras.layers.Conv2D(64, (3, 3), activation='relu'),
    keras.layers.MaxPooling2D((2, 2)),
    keras.layers.Flatten(),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])
# νλΌλ―Έν„° μ: ~100K
```

### μμƒ μ„±λ¥ (CPU)

| λ¨λΈ | ν•™μµ μ‹κ°„ | μ •ν™•λ„ | λ©”λ¨λ¦¬ |
|------|----------|-------|--------|
| MLP | 5-10λ¶„ | ~97% | 2-3GB |
| CNN | 20-30λ¶„ | ~99% | 3-4GB |

---

## PyTorch κ°€λ¥μ„± ν‰κ°€

### β… κ°€λ¥ μ—¬λ¶€: **κ°€λ¥**

### ν•„μ” μ‘μ—…

1. **λΌμ΄λΈλ¬λ¦¬ μ¶”κ°€**
   ```
   torch>=2.1.0,<2.3.0
   torchvision>=0.16.0
   ```

2. **λ¦¬μ†μ¤ μ”κµ¬μ‚¬ν•­**
   - TensorFlowμ™€ λ™μΌ:
     - CPU: 2-4 cores (CNNμ€ 4+ κ¶μ¥)
     - Memory: 4-6GB

3. **Docker μ„¤μ • λ³€κ²½**
   - TensorFlowμ™€ λ™μΌν• λ¦¬μ†μ¤ μ¦κ°€ ν•„μ”

4. **MLflow ν†µν•©**
   - MLflowλ” PyTorch autologging μ§€μ›
   - `mlflow.pytorch.autolog()` μ‚¬μ© κ°€λ¥

5. **MNIST λ°μ΄ν„°μ…‹**
   - `torchvision.datasets.MNIST` μ‚¬μ©
   - μλ™ λ‹¤μ΄λ΅λ“ (μ•½ 11MB)

### λ¨λΈ μ•„ν‚¤ν…μ²

**MNIST MLP**:
```python
import torch.nn as nn

class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(28*28, 128)
        self.dropout = nn.Dropout(0.2)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.flatten(x)
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x
```

**MNIST CNN**:
```python
class CNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 32, 3)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(32, 64, 3)
        self.fc1 = nn.Linear(64 * 5 * 5, 64)
        self.fc2 = nn.Linear(64, 10)

    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = x.view(-1, 64 * 5 * 5)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x
```

### μμƒ μ„±λ¥ (CPU)

- TensorFlowμ™€ κ±°μ λ™μΌ

---

## μΈν”„λΌ μ”κµ¬μ‚¬ν•­

### ν„μ¬ λ¦¬μ†μ¤

```yaml
airflow-worker:
  deploy:
    resources:
      limits:
        cpus: '2'
        memory: 2G
```

### κ¶μ¥ λ¦¬μ†μ¤ (λ¨λ“  λ¨λΈ ν¬ν•¨)

**μµμ† μ”κµ¬μ‚¬ν•­**:
```yaml
airflow-worker:
  deploy:
    resources:
      limits:
        cpus: '4'
        memory: 6G
      reservations:
        cpus: '2'
        memory: 4G
```

**μ΄μƒμ  μ”κµ¬μ‚¬ν•­** (λ” λΉ λ¥Έ ν•™μµ):
```yaml
airflow-worker:
  deploy:
    resources:
      limits:
        cpus: '8'
        memory: 8G
      reservations:
        cpus: '4'
        memory: 6G
```

### λ””μ¤ν¬ κ³µκ°„

- λΌμ΄λΈλ¬λ¦¬: TensorFlow (~500MB) + PyTorch (~800MB) = **~1.3GB**
- MNIST λ°μ΄ν„°: **~50MB** (μ••μ¶• ν•΄μ  ν¬ν•¨)
- λ¨λΈ μ²΄ν¬ν¬μΈνΈ: λ¨λΈλ‹Ή **~10MB**
- **μ΄**: **~2GB** μ¶”κ°€ ν•„μ”

### GPU μ§€μ› (μ„ νƒμ‚¬ν•­)

ν„μ¬ μ„¤μ •μ—λ” GPU μ—†μ. GPU μ¶”κ°€ μ‹:
- NVIDIA Docker runtime μ„¤μ • ν•„μ”
- `tensorflow-gpu` λλ” `torch` (CUDA μ§€μ›) μ„¤μΉ
- ν•™μµ μ†λ„: 10-100λ°° ν–¥μƒ

---

## μ μ•½μ‚¬ν•­ λ° μ„ν—μ”μ†

### 1. λ©”λ¨λ¦¬ μ μ•½

- **ν„μ¬**: Airflow worker 2GB
- **DL λ¨λΈ ν•„μ”**: 4-6GB
- **ν•΄κ²°**: Docker λ¦¬μ†μ¤ μ ν• μ¦κ°€

### 2. CPU μ„±λ¥

- **ν„μ¬**: 2 cores
- **DL ν•™μµ**: λλ¦΄ μ μμ (20-30λ¶„/epoch)
- **ν•΄κ²°**: CPU μ¦κ°€ λλ” epoch μ κ°μ†

### 3. λΌμ΄λΈλ¬λ¦¬ ν¬κΈ°

- TensorFlow + PyTorch = ~1.3GB
- Docker μ΄λ―Έμ§€ ν¬κΈ° μ¦κ°€
- **ν•΄κ²°**: λΉλ“ μ‹κ°„ μ¦κ°€ κ°μ

### 4. λ²„μ „ νΈν™μ„±

- TensorFlowμ™€ PyTorchλ” numpy λ²„μ „ μ¶©λ κ°€λ¥
- **ν•΄κ²°**: νΈν™ κ°€λ¥ν• λ²„μ „ μ„ νƒ
  ```
  numpy>=1.23.0,<2.0.0
  tensorflow>=2.15.0
  torch>=2.1.0
  ```

### 5. MLflow λ΅κΉ…

- DL λ¨λΈμ€ λ΅κ·Έ λ°μ΄ν„°κ°€ λ§μ (λ©”νΈλ¦­, κ·Έλν”„, μ²΄ν¬ν¬μΈνΈ)
- **ν•΄κ²°**: S3 artifact storage ν™μ© (μ΄λ―Έ κµ¬μ„±λ¨)

### 6. ν•™μµ μ‹κ°„

- CPU κΈ°λ° ν•™μµμ€ μ‹κ°„ μ†μ”
- Airflow task timeout μ„¤μ • ν•„μ”
- **ν•΄κ²°**: DAGμ—μ„ `execution_timeout` μ¦κ°€
  ```python
  task = PythonOperator(
      ...
      execution_timeout=timedelta(hours=2)
  )
  ```

---

## κ²°λ΅ 

### μΆ…ν•© ν‰κ°€

| λ¨λΈ | κ°€λ¥ μ—¬λ¶€ | λ‚μ΄λ„ | λ¦¬μ†μ¤ μ¦κ°€ | μ°μ„ μμ„ |
|------|----------|-------|------------|---------|
| **XGBoost** | β… | μ‰¬μ›€ | λ¶ν•„μ” | 1 (κ°€μ¥ λ†’μ) |
| **LightGBM** | β… | μ‰¬μ›€ | λ¶ν•„μ” | 2 |
| **TF MNIST MLP** | β… | μ¤‘κ°„ | λ©”λ¨λ¦¬ 2β†’4GB | 3 |
| **TF MNIST CNN** | β… | μ¤‘κ°„ | λ©”λ¨λ¦¬ 2β†’6GB, CPU 2β†’4 | 4 |
| **PyTorch MLP** | β… | μ¤‘κ°„ | λ©”λ¨λ¦¬ 2β†’4GB | 5 |
| **PyTorch CNN** | β… | μ¤‘κ°„ | λ©”λ¨λ¦¬ 2β†’6GB, CPU 2β†’4 | 6 |

### κ¶μ¥ μ‚¬ν•­

1. **1λ‹¨κ³„: Traditional ML (XGBoost, LightGBM)**
   - λ¦¬μ†μ¤ μ¦κ°€ λ¶ν•„μ”
   - λΉ λ¥Έ κµ¬ν„ λ° ν…μ¤νΈ κ°€λ¥
   - MLflow ν†µν•© κ²€μ¦

2. **2λ‹¨κ³„: Deep Learning (TensorFlow/PyTorch)**
   - Docker λ¦¬μ†μ¤ μ¦κ°€ ν›„ κµ¬ν„
   - MNIST MLPλ¶€ν„° μ‹μ‘ (λ” κ°„λ‹¨ν•¨)
   - CNNμ€ λ§μ§€λ§‰μ— κµ¬ν„

3. **3λ‹¨κ³„: μµμ ν™”**
   - GPU μ¶”κ°€ κ³ λ ¤ (μ„ νƒμ‚¬ν•­)
   - λ¶„μ‚° ν•™μµ (μ„ νƒμ‚¬ν•­)

### μµμΆ… λ‹µλ³€

**μ§λ¬Έ**: "μ§€κΈ μ΄ ν”„λ΅μ νΈμ—μ„ ML XGBoost, LightGBM, DL MNIST MLP, CNN λ‹¤ λ™μ‘μ‹ν‚¬ μ μμ§€?"

**λ‹µλ³€**:
β… **κ°€λ¥ν•©λ‹λ‹¤!**

- **XGBoost, LightGBM**: ν„μ¬ μΈν”„λΌλ΅ μ¦‰μ‹ κ°€λ¥
- **TensorFlow/PyTorch MNIST MLP, CNN**: Docker λ¦¬μ†μ¤ μ¦κ°€ ν›„ κ°€λ¥
  - λ©”λ¨λ¦¬: 2GB β†’ 4-6GB
  - CPU: 2 cores β†’ 4+ cores (κ¶μ¥)

λ¨λ“  λ¨λΈμ€ Airflow DAGλ΅ μλ™ν™” κ°€λ¥ν•λ©°, MLflowλ΅ μ‹¤ν— μ¶”μ  κ°€λ¥ν•©λ‹λ‹¤.

---

**λ‹¤μ**: [κµ¬ν„ κ°€μ΄λ“ μ½κΈ° β†’](02-IMPLEMENTATION_GUIDE.md)
