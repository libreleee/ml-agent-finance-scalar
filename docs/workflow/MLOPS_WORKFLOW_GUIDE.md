# MLOps ì›Œí¬í”Œë¡œìš° ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ì‹œì‘í•˜ê¸°](#ì‹œì‘í•˜ê¸°)
3. [MLOps ìŠ¤íƒ ì‹¤í–‰](#mlops-ìŠ¤íƒ-ì‹¤í–‰)
4. [Airflow ì‚¬ìš©ë²•](#airflow-ì‚¬ìš©ë²•)
5. [MLflow ì‚¬ìš©ë²•](#mlflow-ì‚¬ìš©ë²•)
6. [DAG ì‘ì„± ê°€ì´ë“œ](#dag-ì‘ì„±-ê°€ì´ë“œ)
7. [ML íŒŒì´í”„ë¼ì¸ ì˜ˆì œ](#ml-íŒŒì´í”„ë¼ì¸-ì˜ˆì œ)
8. [ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…](#ëª¨ë‹ˆí„°ë§-ë°-ë””ë²„ê¹…)
9. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## ê°œìš”

### ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MLOps Workflow Stack                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚   Airflow    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   MLflow     â”‚                      â”‚
â”‚  â”‚  (Workflow)  â”‚         â”‚ (Tracking)   â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚         â”‚                         â”‚                              â”‚
â”‚         â”‚                         â”‚                              â”‚
â”‚         â–¼                         â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚    Trino     â”‚         â”‚  SeaweedFS   â”‚                      â”‚
â”‚  â”‚   (Query)    â”‚         â”‚   (S3 API)   â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚         â”‚                         â”‚                              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                   â–¼                                              â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚           â”‚   Iceberg    â”‚                                       â”‚
â”‚           â”‚  Data Lake   â”‚                                       â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì£¼ìš” ì»´í¬ë„ŒíŠ¸

| ì»´í¬ë„ŒíŠ¸ | ì—­í•  | í¬íŠ¸ |
|---------|------|------|
| **Airflow Webserver** | DAG ê´€ë¦¬ UI | 8082 |
| **Airflow Scheduler** | DAG ìŠ¤ì¼€ì¤„ë§ | - |
| **Airflow Worker** | Task ì‹¤í–‰ | - |
| **MLflow** | ì‹¤í—˜ ì¶”ì  & ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ | 5000 |
| **PostgreSQL** | Airflow ë©”íƒ€ë°ì´í„° | - |
| **Redis** | Celery ë©”ì‹œì§€ ë¸Œë¡œì»¤ | 6379 |

---

## ì‹œì‘í•˜ê¸°

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­

- Docker ë° Docker Compose ì„¤ì¹˜
- ìµœì†Œ 8GB RAM
- ìµœì†Œ 20GB ë””ìŠ¤í¬ ê³µê°„
- ê¸°ì¡´ Lakehouse ì¸í”„ë¼ ì‹¤í–‰ ì¤‘

### ì ‘ì† ì •ë³´

| ì„œë¹„ìŠ¤ | URL | ê³„ì • |
|--------|-----|------|
| Airflow UI | http://localhost:8082 | admin / admin |
| MLflow UI | http://localhost:5000 | (ì¸ì¦ ì—†ìŒ) |

---

## MLOps ìŠ¤íƒ ì‹¤í–‰

### 1ï¸âƒ£ ì „ì²´ ìŠ¤íƒ ì‹œì‘

```bash
cd /home/i/work/ai/lakehouse-tick

# 1ë‹¨ê³„: Lakehouse ì¸í”„ë¼ í™•ì¸ (ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•¨)
docker compose ps

# 2ë‹¨ê³„: MLOps ìŠ¤íƒ ì‹œì‘
docker compose -f docker-compose-mlops.yml up -d

# 3ë‹¨ê³„: ìƒíƒœ í™•ì¸
docker compose -f docker-compose-mlops.yml ps
```

**ì˜ˆìƒ ì¶œë ¥**:
```
NAME                    STATUS              PORTS
airflow-postgres        Up (healthy)        5432/tcp
airflow-redis           Up (healthy)        0.0.0.0:6379->6379/tcp
airflow-scheduler       Up (healthy)        8080/tcp
airflow-webserver       Up (healthy)        0.0.0.0:8082->8080/tcp
airflow-worker          Up (healthy)        8080/tcp
mlflow                  Up (healthy)        0.0.0.0:5000->5000/tcp
```

### 2ï¸âƒ£ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸

```bash
# í—¬ìŠ¤ì²´í¬
curl http://localhost:5000/health  # MLflow
curl http://localhost:8082/health  # Airflow

# ë¡œê·¸ í™•ì¸
docker compose -f docker-compose-mlops.yml logs -f mlflow
docker compose -f docker-compose-mlops.yml logs -f airflow-scheduler
```

### 3ï¸âƒ£ ì„œë¹„ìŠ¤ ì¤‘ì§€

```bash
# MLOps ìŠ¤íƒë§Œ ì¤‘ì§€ (ë°ì´í„° ìœ ì§€)
docker compose -f docker-compose-mlops.yml stop

# MLOps ìŠ¤íƒ ì™„ì „ ì œê±° (ë°ì´í„° ë³´ì¡´)
docker compose -f docker-compose-mlops.yml down

# MLOps ìŠ¤íƒ ì™„ì „ ì œê±° (ë°ì´í„° ì‚­ì œ)
docker compose -f docker-compose-mlops.yml down -v
```

---

## Airflow ì‚¬ìš©ë²•

### UI ì ‘ì†

1. ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8082 ì ‘ì†
2. ë¡œê·¸ì¸: `admin` / `admin`

### DAG ê´€ë¦¬

#### DAG ëª©ë¡ í™•ì¸

```bash
docker exec airflow-scheduler airflow dags list
```

#### DAG í™œì„±í™”/ë¹„í™œì„±í™”

**UIì—ì„œ**:
1. DAGs í˜ì´ì§€ ì ‘ì†
2. DAG ì˜†ì˜ í† ê¸€ ìŠ¤ìœ„ì¹˜ í´ë¦­

**CLIì—ì„œ**:
```bash
# í™œì„±í™”
docker exec airflow-scheduler airflow dags unpause ml_pipeline_end_to_end

# ë¹„í™œì„±í™”
docker exec airflow-scheduler airflow dags pause ml_pipeline_end_to_end
```

#### DAG ìˆ˜ë™ ì‹¤í–‰

**UIì—ì„œ**:
1. DAG ì´ë¦„ í´ë¦­
2. ìš°ì¸¡ ìƒë‹¨ "Trigger DAG" ë²„íŠ¼ í´ë¦­

**CLIì—ì„œ**:
```bash
docker exec airflow-scheduler airflow dags trigger ml_pipeline_end_to_end
```

#### DAG ì‹¤í–‰ ì´ë ¥ í™•ì¸

```bash
# ìµœê·¼ ì‹¤í–‰ ì´ë ¥
docker exec airflow-scheduler airflow dags list-runs -d ml_pipeline_end_to_end

# íŠ¹ì • ì‹¤í–‰ì˜ Task ìƒíƒœ
docker exec airflow-scheduler airflow tasks states-for-dag-run \
  ml_pipeline_end_to_end \
  manual__2025-12-25T15:12:37+00:00
```

### Task ê´€ë¦¬

#### Task ë¡œê·¸ í™•ì¸

**UIì—ì„œ**:
1. DAG ì‹¤í–‰ í´ë¦­
2. Task í´ë¦­
3. "Log" íƒ­ ì„ íƒ

**CLIì—ì„œ**:
```bash
docker exec airflow-scheduler airflow tasks logs \
  ml_pipeline_end_to_end \
  raw_to_bronze \
  2025-12-25
```

#### Task ì¬ì‹¤í–‰

**UIì—ì„œ**:
1. ì‹¤íŒ¨í•œ Task í´ë¦­
2. "Clear" ë²„íŠ¼ í´ë¦­

**CLIì—ì„œ**:
```bash
docker exec airflow-scheduler airflow tasks clear \
  ml_pipeline_end_to_end \
  --task-regex "raw_to_bronze" \
  --start-date 2025-12-25 \
  --end-date 2025-12-25
```

### ì‚¬ìš©ì ê´€ë¦¬

#### ìƒˆ ì‚¬ìš©ì ì¶”ê°€

```bash
docker exec airflow-webserver airflow users create \
  --username data_analyst \
  --firstname Data \
  --lastname Analyst \
  --role Viewer \
  --email analyst@example.com \
  --password analyst123
```

#### ì‚¬ìš©ì ì—­í• 

| ì—­í•  | ê¶Œí•œ |
|------|------|
| **Admin** | ëª¨ë“  ê¶Œí•œ |
| **Op** | DAG ì‹¤í–‰/ì¤‘ì§€ |
| **Viewer** | ì½ê¸° ì „ìš© |
| **User** | DAG ì‹¤í–‰ë§Œ ê°€ëŠ¥ |

---

## MLflow ì‚¬ìš©ë²•

### UI ì ‘ì†

ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:5000 ì ‘ì†

### ì‹¤í—˜ ê´€ë¦¬

#### ì‹¤í—˜ ëª©ë¡ í™•ì¸

**UIì—ì„œ**: ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ "Experiments" í™•ì¸

**CLIì—ì„œ**:
```bash
curl -s "http://localhost:5000/api/2.0/mlflow/experiments/search?max_results=100"
```

#### ì‹¤í—˜ ìƒì„±

**Python ì½”ë“œ**:
```python
import mlflow

mlflow.set_tracking_uri("http://mlflow:5000")
mlflow.set_experiment("my-experiment")

with mlflow.start_run():
    mlflow.log_param("learning_rate", 0.01)
    mlflow.log_metric("accuracy", 0.95)
```

### ëª¨ë¸ ê´€ë¦¬

#### ëª¨ë¸ ë¡œê¹…

```python
import mlflow.sklearn
from sklearn.ensemble import RandomForestClassifier

# ëª¨ë¸ í•™ìŠµ
model = RandomForestClassifier(n_estimators=100)
model.fit(X_train, y_train)

# MLflowì— ë¡œê¹…
with mlflow.start_run():
    mlflow.log_param("n_estimators", 100)
    mlflow.sklearn.log_model(model, "model")
```

#### ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡

```python
from mlflow.tracking import MlflowClient

client = MlflowClient("http://mlflow:5000")

# ëª¨ë¸ ë“±ë¡
model_uri = f"runs:/{run_id}/model"
model_version = mlflow.register_model(model_uri, "my-model")

# Productionìœ¼ë¡œ ì „í™˜
client.transition_model_version_stage(
    name="my-model",
    version=model_version.version,
    stage="Production"
)
```

#### Production ëª¨ë¸ ë¡œë“œ

```python
import mlflow.sklearn

model = mlflow.sklearn.load_model("models:/my-model/Production")
predictions = model.predict(X_test)
```

---

## DAG ì‘ì„± ê°€ì´ë“œ

### DAG íŒŒì¼ ìœ„ì¹˜

```
/home/i/work/ai/lakehouse-tick/
â””â”€â”€ dags/
    â”œâ”€â”€ ml_pipeline_dag.py          # ë©”ì¸ DAG
    â”œâ”€â”€ data_ingestion_dag.py       # ë°ì´í„° ìˆ˜ì§‘ DAG
    â””â”€â”€ scripts/
        â”œâ”€â”€ bronze_layer.py         # Bronze ë ˆì´ì–´ ìŠ¤í¬ë¦½íŠ¸
        â”œâ”€â”€ silver_layer.py         # Silver ë ˆì´ì–´ ìŠ¤í¬ë¦½íŠ¸
        â””â”€â”€ gold_layer.py           # Gold ë ˆì´ì–´ ìŠ¤í¬ë¦½íŠ¸
```

### ê¸°ë³¸ DAG êµ¬ì¡°

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta

# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'data-team',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
}

# DAG ì •ì˜
dag = DAG(
    'my_dag',
    default_args=default_args,
    description='My first DAG',
    schedule_interval='0 2 * * *',  # ë§¤ì¼ 02:00
    start_date=datetime(2025, 12, 25),
    catchup=False,
    tags=['example'],
)

# Task í•¨ìˆ˜
def my_task(**context):
    print("Hello from Airflow!")
    return "Success"

# Task ì •ì˜
task1 = PythonOperator(
    task_id='my_task',
    python_callable=my_task,
    dag=dag,
)
```

### Task ì˜ì¡´ì„± ì •ì˜

```python
# ìˆœì°¨ ì‹¤í–‰
task1 >> task2 >> task3

# ë³‘ë ¬ ì‹¤í–‰ í›„ í•©ë¥˜
task1 >> [task2, task3] >> task4

# ë³µì¡í•œ ì˜ì¡´ì„±
(task1 >> task2) & (task3 >> task4) >> task5
```

### MLflow í†µí•©

```python
from airflow.operators.python import PythonOperator
import mlflow

def train_model(**context):
    mlflow.set_tracking_uri("http://mlflow:5000")
    mlflow.set_experiment("my-experiment")

    with mlflow.start_run(run_name=context['task_instance'].task_id):
        # íŒŒë¼ë¯¸í„° ë¡œê¹…
        mlflow.log_param("dag_id", context['dag'].dag_id)
        mlflow.log_param("execution_date", str(context['execution_date']))

        # ëª¨ë¸ í•™ìŠµ
        accuracy = 0.95

        # ë©”íŠ¸ë¦­ ë¡œê¹…
        mlflow.log_metric("accuracy", accuracy)

        return accuracy

train_task = PythonOperator(
    task_id='train_model',
    python_callable=train_model,
    dag=dag,
)
```

### Trino ì¿¼ë¦¬ ì‹¤í–‰

```python
from airflow.providers.trino.operators.trino import TrinoOperator

query_task = TrinoOperator(
    task_id='run_query',
    trino_conn_id='trino_default',
    sql="""
        SELECT symbol, AVG(last_price) as avg_price
        FROM hive_prod.option_ticks_db.bronze_option_ticks
        WHERE DATE(timestamp) = CURRENT_DATE - INTERVAL '1' DAY
        GROUP BY symbol
    """,
    dag=dag,
)
```

---

## ML íŒŒì´í”„ë¼ì¸ ì˜ˆì œ

### End-to-End ML íŒŒì´í”„ë¼ì¸

ì´ë¯¸ ì‘ì„±ëœ [dags/ml_pipeline_dag.py](../../dags/ml_pipeline_dag.py) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

íŒŒì´í”„ë¼ì¸ ë‹¨ê³„:

```
1. raw_to_bronze        â†’ ì›ì‹œ ë°ì´í„° ìˆ˜ì§‘
2. bronze_to_silver     â†’ ë°ì´í„° ì •ì œ
3. silver_to_gold       â†’ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì ìš©
4. feature_engineering  â†’ ML í”¼ì²˜ ìƒì„±
5. model_training       â†’ ëª¨ë¸ í•™ìŠµ (MLflow ë¡œê¹…)
6. model_evaluation     â†’ ëª¨ë¸ í‰ê°€
7. model_registry       â†’ MLflow ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë“±ë¡
```

### ì‹¤í–‰ ë°©ë²•

```bash
# 1. DAG í™œì„±í™”
docker exec airflow-scheduler airflow dags unpause ml_pipeline_end_to_end

# 2. ìˆ˜ë™ ì‹¤í–‰
docker exec airflow-scheduler airflow dags trigger ml_pipeline_end_to_end

# 3. ì‹¤í–‰ ìƒíƒœ í™•ì¸
docker exec airflow-scheduler airflow dags list-runs -d ml_pipeline_end_to_end
```

### ì‹¤í–‰ ê²°ê³¼ í™•ì¸

**Airflow UI**:
1. http://localhost:8082 ì ‘ì†
2. `ml_pipeline_end_to_end` DAG í´ë¦­
3. Graph Viewì—ì„œ ì‹¤í–‰ ìƒíƒœ í™•ì¸

**MLflow UI**:
1. http://localhost:5000 ì ‘ì†
2. "lakehouse_ml_pipeline" ì‹¤í—˜ í´ë¦­
3. ê° Runì˜ íŒŒë¼ë¯¸í„° ë° ë©”íŠ¸ë¦­ í™•ì¸

---

## ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…

### ë¡œê·¸ í™•ì¸

#### ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§

```bash
# ì „ì²´ ë¡œê·¸
docker compose -f docker-compose-mlops.yml logs -f

# íŠ¹ì • ì„œë¹„ìŠ¤
docker compose -f docker-compose-mlops.yml logs -f airflow-scheduler
docker compose -f docker-compose-mlops.yml logs -f airflow-worker
docker compose -f docker-compose-mlops.yml logs -f mlflow
```

#### ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜

```
/home/i/work/ai/lakehouse-tick/
â””â”€â”€ logs/
    â”œâ”€â”€ airflow/
    â”‚   â”œâ”€â”€ scheduler/
    â”‚   â”‚   â””â”€â”€ 2025-12-25/
    â”‚   â”‚       â””â”€â”€ dag_processor_manager.log
    â”‚   â””â”€â”€ dag_id=ml_pipeline_end_to_end/
    â”‚       â””â”€â”€ run_id=manual__2025-12-25T15:12:37+00:00/
    â”‚           â””â”€â”€ task_id=raw_to_bronze/
    â””â”€â”€ mlflow/
```

### ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§

```bash
# ì‹¤ì‹œê°„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ 
docker stats mlflow airflow-webserver airflow-scheduler airflow-worker

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
docker system df -v | grep -E 'mlflow|airflow'
```

### ì„±ëŠ¥ ë©”íŠ¸ë¦­

#### Airflow ë©”íŠ¸ë¦­

```bash
# ì‹¤í–‰ ì¤‘ì¸ Task ìˆ˜
docker exec airflow-scheduler airflow dags list-runs --state running

# ì‹¤íŒ¨í•œ Task ìˆ˜
docker exec airflow-scheduler airflow dags list-runs --state failed
```

#### MLflow ë©”íŠ¸ë¦­

```bash
# ì‹¤í—˜ ìˆ˜
curl -s "http://localhost:5000/api/2.0/mlflow/experiments/search?max_results=100" | grep -c experiment_id

# Run ìˆ˜
curl -s "http://localhost:5000/api/2.0/mlflow/runs/search?max_results=100" | grep -c run_id
```

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: DAGê°€ ì¸ì‹ë˜ì§€ ì•ŠìŒ

**ì¦ìƒ**: Airflow UIì— DAGê°€ í‘œì‹œë˜ì§€ ì•ŠìŒ

**ì›ì¸**:
- Python ë¬¸ë²• ì—ëŸ¬
- íŒŒì¼ ê¶Œí•œ ë¬¸ì œ
- Schedulerê°€ íŒŒì¼ì„ ì•„ì§ ì½ì§€ ì•ŠìŒ

**í•´ê²°**:
```bash
# 1. Python ë¬¸ë²• ê²€ì‚¬
docker exec airflow-scheduler python /opt/airflow/dags/ml_pipeline_dag.py

# 2. íŒŒì¼ ê¶Œí•œ í™•ì¸
ls -la /home/i/work/ai/lakehouse-tick/dags/

# 3. ê¶Œí•œ ìˆ˜ì •
chmod 644 /home/i/work/ai/lakehouse-tick/dags/*.py

# 4. Scheduler ì¬ì‹œì‘
docker compose -f docker-compose-mlops.yml restart airflow-scheduler

# 5. ë¡œê·¸ í™•ì¸
docker compose -f docker-compose-mlops.yml logs airflow-scheduler | tail -50
```

---

### ë¬¸ì œ 2: Task ì‹¤í–‰ ì‹¤íŒ¨

**ì¦ìƒ**: Task ìƒíƒœê°€ "failed"

**í•´ê²°**:
```bash
# 1. Task ë¡œê·¸ í™•ì¸
docker exec airflow-scheduler airflow tasks logs \
  ml_pipeline_end_to_end \
  raw_to_bronze \
  2025-12-25

# 2. Worker ë¡œê·¸ í™•ì¸
docker compose -f docker-compose-mlops.yml logs airflow-worker | grep ERROR

# 3. Task ì¬ì‹¤í–‰
docker exec airflow-scheduler airflow tasks clear \
  ml_pipeline_end_to_end \
  --task-regex "raw_to_bronze" \
  --start-date 2025-12-25 \
  --end-date 2025-12-25
```

---

### ë¬¸ì œ 3: MLflow ì—°ê²° ì‹¤íŒ¨

**ì¦ìƒ**: Taskì—ì„œ MLflowì— ë¡œê¹…í•˜ì§€ ëª»í•¨

**í•´ê²°**:
```bash
# 1. MLflow ìƒíƒœ í™•ì¸
curl http://localhost:5000/health

# 2. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í…ŒìŠ¤íŠ¸ (Workerì—ì„œ)
docker exec airflow-worker curl http://mlflow:5000/health

# 3. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
docker exec airflow-worker env | grep MLFLOW

# 4. MLflow ì¬ì‹œì‘
docker compose -f docker-compose-mlops.yml restart mlflow
```

---

### ë¬¸ì œ 4: ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì¦ìƒ**: Worker ì»¨í…Œì´ë„ˆê°€ ì¬ì‹œì‘ë¨

**í•´ê²°**:
```bash
# 1. í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
docker stats --no-stream

# 2. docker-compose-mlops.yml ìˆ˜ì •
# Workerì˜ ë©”ëª¨ë¦¬ ì œí•œ ì¦ê°€:
#   deploy.resources.limits.memory: 4G  # 2G â†’ 4G

# 3. ì¬ì‹œì‘
docker compose -f docker-compose-mlops.yml restart airflow-worker
```

---

### ë¬¸ì œ 5: Taskê°€ íì—ì„œ ëŒ€ê¸° ì¤‘

**ì¦ìƒ**: Task ìƒíƒœê°€ "queued"ì—ì„œ ë³€í•˜ì§€ ì•ŠìŒ

**ì›ì¸**: Workerê°€ ì‹¤í–‰ ì¤‘ì´ì§€ ì•ŠìŒ

**í•´ê²°**:
```bash
# 1. Worker ìƒíƒœ í™•ì¸
docker compose -f docker-compose-mlops.yml ps airflow-worker

# 2. Worker ë¡œê·¸ í™•ì¸
docker compose -f docker-compose-mlops.yml logs airflow-worker | grep "celery@"

# 3. Workerê°€ ì¤‘ì§€ë˜ì–´ ìˆë‹¤ë©´ ì‹œì‘
docker compose -f docker-compose-mlops.yml up -d airflow-worker

# 4. Celery ìƒíƒœ í™•ì¸
docker exec airflow-worker celery --app airflow.executors.celery_executor.app inspect ping
```

---

## ë¹ ë¥¸ ì°¸ì¡°

### ìì£¼ ì‚¬ìš©í•˜ëŠ” ëª…ë ¹ì–´

```bash
# ìŠ¤íƒ ì‹œì‘
docker compose -f docker-compose-mlops.yml up -d

# ìŠ¤íƒ ì¤‘ì§€
docker compose -f docker-compose-mlops.yml stop

# DAG ëª©ë¡
docker exec airflow-scheduler airflow dags list

# DAG ì‹¤í–‰
docker exec airflow-scheduler airflow dags trigger <dag_id>

# DAG ì‹¤í–‰ ì´ë ¥
docker exec airflow-scheduler airflow dags list-runs -d <dag_id>

# Task ë¡œê·¸
docker exec airflow-scheduler airflow tasks logs <dag_id> <task_id> <execution_date>

# ì„œë¹„ìŠ¤ ë¡œê·¸
docker compose -f docker-compose-mlops.yml logs -f <service_name>

# ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
docker stats mlflow airflow-webserver airflow-scheduler airflow-worker
```

### URL ë¹ ë¥¸ ì ‘ì†

| ì„œë¹„ìŠ¤ | URL | ìš©ë„ |
|--------|-----|------|
| Airflow | http://localhost:8082 | DAG ê´€ë¦¬ |
| MLflow | http://localhost:5000 | ì‹¤í—˜ ì¶”ì  |
| Trino | http://localhost:8080/ui | ì¿¼ë¦¬ ëª¨ë‹ˆí„°ë§ |
| Superset | http://localhost:8088 | BI ëŒ€ì‹œë³´ë“œ |
| Grafana | http://localhost:3000 | ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ |

---

## ë‹¤ìŒ ë‹¨ê³„

1. **[ì‹¤ì „ ì˜ˆì œ](./MLOPS_EXAMPLES.md)**: ì‹¤ì œ ìœ ìŠ¤ì¼€ì´ìŠ¤ ê¸°ë°˜ DAG ì‘ì„±
2. **[ì„±ëŠ¥ ìµœì í™”](./MLOPS_OPTIMIZATION.md)**: Airflow ë° MLflow íŠœë‹
3. **[ë³´ì•ˆ ê°€ì´ë“œ](./MLOPS_SECURITY.md)**: RBAC, SSL/TLS ì„¤ì •
4. **[CI/CD í†µí•©](./MLOPS_CICD.md)**: Jenkins/GitHub Actions ì—°ë™

---

**ì‘ì„±**: 2025-12-26
**ë²„ì „**: 1.0
**ê´€ë ¨ ë¬¸ì„œ**:
- [END_TO_END_ML_PIPELINE_MONITORING_SOLUTIONS.md](../feature/visualization/END_TO_END_ML_PIPELINE_MONITORING_SOLUTIONS.md)
- [START_HERE.md](../../START_HERE.md)
