# DAG Separation Strategy (Copilot — GPT-5.2)

## 핵심 결론
네 가지 케이스(이미지 DL 2개, 시계열 1개, 탭형 ML 1개)를 운영한다고 가정하면,
현업에서 가장 흔한 방식은 **“워크로드(운영 성격) 기준으로 DAG는 분리하고, 공통 코드는 템플릿/모듈로 공유”** 입니다.

- 데이터셋별로 DAG를 4개 만드는 방식은 데모/초기에는 빠르지만, 운영 단계에서는 중복과 복잡도가 커지기 쉽습니다.
- 대신 **DAG는 2~3개 정도로 묶고**, 모델/데이터별 설정(config)으로 세부 동작을 바꾸는 구성이 자주 선택됩니다.

---

## 왜 이 방식이 현업에서 가장 흔한가
### 1) 리소스 격리 (가장 큰 이유)
- DL(CNN)은 GPU/대용량 메모리/긴 실행시간이 필요한 경우가 많음
- ML(LightGBM)은 CPU 위주로 빠르게 돌고 병렬 학습 설정이 중요함
- 워크로드를 같은 DAG/같은 실행환경에 섞으면, **스케줄 지연·큐 밀림·장애 전파**가 쉽게 발생

### 2) 스케줄·재시도·SLA 정책 분리
- Tick(시계열)은 배치 윈도우/데이터 준비/백필 정책이 중요하고 재처리 비용이 큼
- 이미지 학습은 실험 성격이 강하거나, GPU 가용성에 따라 스케줄 정책이 달라질 수 있음

### 3) 의존성/배포 단위 분리
- PyTorch/TF 같은 DL 스택과 LightGBM/Tabular 스택은 라이브러리/이미지 구성이 크게 다름
- 모델별 이미지 분리로 빌드/보안/취약점 관리가 쉬워짐

### 4) 운영 가시성/책임 분리
- DAG 단위로 owner, alert 채널, SLA, on-call 책임을 나누기 쉽고
- Airflow UI에서도 문제 원인 파악이 빠름

---

## 권장 구조 (가장 많이 쓰는 형태)
### A. 공통 코드 레이어 (재사용)
- 공통 흐름: 데이터 준비 → 학습 → 평가 → (선택) 등록/승격
- 공통 기능: MLflow 로깅, 아티팩트 저장, 모델 레지스트리 연동, 공통 메트릭

### B. DAG 레이어 (운영 성격 기준 분리)
다음 중 2~3개로 나누는 구성이 흔합니다.

1) **image_dl_training DAG**
- 대상: MNIST CNN, CIFAR10 CNN(또는 유사 이미지 분류)
- 특징: GPU pool/queue 사용, DL 컨테이너 이미지 사용

2) **time_series_training DAG**
- 대상: Tick data 기반 예측/분류
- 특징: 데이터 준비 Sensor/백필 정책/시간 파티션 관리에 최적화

3) **tabular_ml_training DAG**
- 대상: 가정집 전력데이터 + LightGBM
- 특징: CPU 중심, 데이터 전처리/피처 관리와 재현성(버전/스키마) 중심

> MNIST용 DAG, CIFAR10용 DAG처럼 “데이터셋마다 DAG”는 상대적으로 덜 흔하고,
> 보통은 “이미지 DL”, “시계열”, “탭형 ML”처럼 **워크로드 타입**으로 묶는 편입니다.

---

## 4개 케이스에 대한 권장 매핑
- **MNIST CNN** → image_dl_training
- **CIFAR10** → image_dl_training
- **Tick data** → time_series_training
- **전력데이터 + LightGBM** → tabular_ml_training

---

## 단일 DAG로도 가능한가?
가능합니다. 특히 데모/POC/초기에는 아래 방식으로 시작하기도 합니다.
- 단일 DAG + `dag_run.conf`로 `task_type(model_type, dataset, resources)` 전달
- 내부에서 분기하여 trainer/이미지/리소스만 바꿈

다만 운영으로 갈수록 아래가 누적되면 분리하는 쪽이 유리합니다.
- GPU/CPU 혼재로 대기열이 꼬임
- 스케줄 정책이 다름(일배치 vs 시간배치 등)
- 장애 전파를 줄여야 함(시계열 파이프라인 보호)

---

## 빠른 의사결정 체크리스트
- GPU가 필요한가? → (예) DL 계열은 별도 DAG 또는 최소한 별도 queue/pool
- 스케줄/백필 정책이 완전히 다른가? → (예) 분리 권장
- 라이브러리/이미지가 크게 다른가? → (예) 분리 권장
- 장애 전파를 줄이고 싶은가? → (예) 분리 권장
- 아직 데모/POC 수준인가? → (예) 단일 DAG + 파라미터로 시작 가능

---

## 추천 “시작점”
- 처음부터 4개 DAG로 나누기보다,
  - **2~3개 DAG(워크로드 기준)로 분리**
  - **공통 코드는 모듈로 재사용**
  - **MLflow 실험/모델 네이밍 규칙 표준화**
이 조합이 운영/유지보수/확장성 측면에서 가장 무난합니다.

---

*작성: GitHub Copilot (GPT-5.2)*
