# DAG ë¶„ë¦¬ ì „ëµ - MLflow + Airflow í˜„ì—… ì „ë¬¸ê°€ ê´€ì 

ì‘ì„±ì¼: 2025-12-28
ì‘ì„±ì: Claude Sonnet 4.5

---

## ğŸ“Š Executive Summary

### **ê²°ë¡ : DAGëŠ” 4ê°œ ë¶„ë¦¬ê°€ í˜„ì—… í‘œì¤€ì…ë‹ˆë‹¤** âœ…

1. **MNIST (CNN)** â†’ ë³„ë„ DAG
2. **CIFAR-10 (CNN)** â†’ ë³„ë„ DAG  
3. **Tick Data** â†’ ë³„ë„ DAG
4. **ì „ë ¥ ë°ì´í„° (LightGBM)** â†’ ë³„ë„ DAG

**íŒŒì¼ ê°œìˆ˜ëŠ” ì„ íƒì‚¬í•­**:
- **ì˜µì…˜ A**: DAG íŒŒì¼ 4ê°œ (ì§ê´€ì , ì†Œê·œëª¨ íŒ€)
- **ì˜µì…˜ B**: Factory íŒ¨í„´ìœ¼ë¡œ íŒŒì¼ 1-2ê°œ (ëŒ€ê·œëª¨, í…œí”Œë¦¿í™”)

---

## ğŸ¯ ì™œ ê°ê° ë³„ë„ DAGë¡œ ë¶„ë¦¬í•´ì•¼ í•˜ë‚˜?

### 4ê°€ì§€ ì›Œí¬í”Œë¡œìš°ì˜ ê·¼ë³¸ì  ì°¨ì´

| êµ¬ë¶„ | MNIST/CIFAR-10 | Tick Data | ì „ë ¥ ë°ì´í„° (LightGBM) |
|------|----------------|-----------|------------------------|
| **ìŠ¤ì¼€ì¤„** | ì‹¤í—˜ìš© (ìˆ˜ë™/ì£¼ê°„) | ì‹¤ì‹œê°„/ì‹œê°„ë‹¨ìœ„ | ì¼/ì£¼ ë°°ì¹˜ |
| **ë¦¬ì†ŒìŠ¤** | GPU í•„ìˆ˜, ì¥ì‹œê°„ | CPU/IO ì§‘ì•½ | CPU ì¤‘ì‹¬, ì§§ìŒ |
| **í”„ë ˆì„ì›Œí¬** | TensorFlow/PyTorch | ë‹¤ì–‘ | LightGBM |
| **ë°ì´í„° í¬ê¸°** | ê³ ì • (ìˆ˜ë§Œì¥) | ìŠ¤íŠ¸ë¦¬ë°/ì¦ë¶„ | ì •í˜• ë°°ì¹˜ |
| **ì¬ì²˜ë¦¬(Backfill)** | ì „ì²´ ì¬í•™ìŠµ | êµ¬ê°„ ë‹¨ìœ„ ì¦ë¶„ | ì¼ ë‹¨ìœ„ |
| **ì‹¤íŒ¨ ì˜í–¥ë„** | ë…ë¦½ ì‹¤í—˜ | ì‹¤ì‹œê°„ ì„œë¹„ìŠ¤ ì˜í–¥ | ë…ë¦½ ë°°ì¹˜ |
| **Ownership** | ë¹„ì „íŒ€ | í€€íŠ¸/íŠ¸ë ˆì´ë”©íŒ€ | ì—ë„ˆì§€íŒ€ |

### í˜„ì—… 5ëŒ€ ë¶„ë¦¬ ì´ìœ 

#### 1. **ìŠ¤ì¼€ì¤„/íŠ¸ë¦¬ê±°ê°€ ì™„ì „íˆ ë‹¤ë¦„**
```python
# MNIST/CIFAR-10: ì‹¤í—˜ì„±
schedule_interval=None  # ìˆ˜ë™ íŠ¸ë¦¬ê±° ë˜ëŠ” ì£¼ 1íšŒ

# Tick Data: ì¤€ì‹¤ì‹œê°„
schedule_interval='*/15 * * * *'  # 15ë¶„ë§ˆë‹¤

# ì „ë ¥ ë°ì´í„°: ì¼ì¼ ë°°ì¹˜
schedule_interval='0 1 * * *'  # ë§¤ì¼ ì˜¤ì „ 1ì‹œ
```

#### 2. **ë¦¬ì†ŒìŠ¤ ê²©ë¦¬ í•„ìˆ˜**
```python
# Airflow Pool ì„¤ì •
'mnist_cnn_training': {
    'pool': 'gpu_pool',
    'priority_weight': 5,
    'queue': 'gpu_queue'
}

'tick_model_training': {
    'pool': 'high_priority_cpu',
    'priority_weight': 10,  # ê°€ì¥ ë†’ì€ ìš°ì„ ìˆœìœ„
    'queue': 'realtime_queue'
}

'power_lgbm_training': {
    'pool': 'default_pool',
    'priority_weight': 3,
    'queue': 'batch_queue'
}
```

#### 3. **ì‹¤íŒ¨ ê²©ë¦¬ (Blast Radius)**
- Tick ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨ê°€ MNIST ì‹¤í—˜ì„ ë©ˆì¶”ë©´ ì•ˆ ë¨
- ê° DAGëŠ” ë…ë¦½ì ìœ¼ë¡œ ì¬ì‹œë„ ì •ì±… ì ìš©
- SLA ì•Œë¦¼ë„ ë³„ë„ ì„¤ì •

#### 4. **Ownership ë¶„ë¦¬ (ì¡°ì§ êµ¬ì¡°)**
```
ë¹„ì „íŒ€       â†’ mnist_cnn_dag.py, cifar10_cnn_dag.py
í€€íŠ¸íŒ€       â†’ tick_model_dag.py
ì—ë„ˆì§€ë¶„ì„íŒ€ â†’ power_lgbm_dag.py
```
- Git PR ë¦¬ë·°ê°€ ëª…í™•
- ë°°í¬ ê¶Œí•œ ë¶„ë¦¬
- ì±…ì„ ì†Œì¬ ëª…í™•

#### 5. **MLflow ì‹¤í—˜ ì¶”ì  ë¶„ë¦¬**
```python
# ê° DAGëŠ” ë…ë¦½ì ì¸ MLflow Experiment ì‚¬ìš©
mlflow.set_experiment("mnist-cnn-experiments")
mlflow.set_experiment("cifar10-cnn-experiments")
mlflow.set_experiment("tick-model-production")
mlflow.set_experiment("power-consumption-forecasting")
```

---

## ğŸ­ í˜„ì—… Best Practice

### Pattern A: íŒŒì¼ ë¶„ë¦¬ (ì§ê´€ì ) - 80% ê¸°ì—…

```
lakehouse-tick/
â””â”€â”€ dags/
    â”œâ”€â”€ ml_mnist_cnn_dag.py          # DAG ID: mnist_cnn_training
    â”œâ”€â”€ ml_cifar10_cnn_dag.py        # DAG ID: cifar10_cnn_training
    â”œâ”€â”€ ml_tick_model_dag.py         # DAG ID: tick_model_training
    â”œâ”€â”€ ml_power_lgbm_dag.py         # DAG ID: power_lgbm_training
    â”‚
    â”œâ”€â”€ common/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ mlflow_utils.py          # MLflow ê³µí†µ í•¨ìˆ˜
    â”‚   â”œâ”€â”€ cnn_training_template.py # CNN ì¬ì‚¬ìš© ì½”ë“œ
    â”‚   â”œâ”€â”€ model_registry.py        # ëª¨ë¸ ë“±ë¡ ë¡œì§
    â”‚   â””â”€â”€ config.py                # ê³µí†µ ì„¤ì •
    â”‚
    â””â”€â”€ scripts/
        â”œâ”€â”€ train_mnist.py
        â”œâ”€â”€ train_cifar10.py
        â”œâ”€â”€ train_tick_model.py
        â””â”€â”€ train_power_lgbm.py
```

**ì¥ì :**
- ê° íŒ€ì´ ë…ë¦½ì ìœ¼ë¡œ ìˆ˜ì • ê°€ëŠ¥
- Git blame/PR ë¦¬ë·°ê°€ ëª…í™•
- ì´ˆë³´ìë„ ì´í•´í•˜ê¸° ì‰¬ì›€
- ë””ë²„ê¹… ê°„í¸

**ë‹¨ì :**
- ê³µí†µ ì½”ë“œ ì¤‘ë³µ ê°€ëŠ¥ì„± (â†’ common ëª¨ë“ˆë¡œ í•´ê²°)
- ì„¤ì • ì¼ê´€ì„± ìœ ì§€ í•„ìš”

### Pattern B: Factory íŒ¨í„´ (ê³ ê¸‰) - 20% ëŒ€ê¸°ì—…

```python
# dags/model_training_factory.py
from airflow import DAG
from datetime import datetime, timedelta
from common.dag_factory import create_ml_training_dag

# ì„¤ì • ê¸°ë°˜ DAG ìƒì„±
TRAINING_CONFIGS = [
    {
        "dag_id": "mnist_cnn_training",
        "schedule": None,
        "model_type": "cnn",
        "framework": "tensorflow",
        "dataset": "mnist",
        "pool": "gpu_pool",
        "tags": ["ml", "cnn", "mnist", "experiment"]
    },
    {
        "dag_id": "cifar10_cnn_training",
        "schedule": None,
        "model_type": "cnn",
        "framework": "pytorch",
        "dataset": "cifar10",
        "pool": "gpu_pool",
        "tags": ["ml", "cnn", "cifar10", "experiment"]
    },
    {
        "dag_id": "tick_model_training",
        "schedule": "*/15 * * * *",
        "model_type": "timeseries",
        "framework": "sklearn",
        "dataset": "tick",
        "pool": "high_priority_cpu",
        "priority_weight": 10,
        "tags": ["ml", "tick", "realtime", "production"]
    },
    {
        "dag_id": "power_lgbm_training",
        "schedule": "0 1 * * *",
        "model_type": "gbm",
        "framework": "lightgbm",
        "dataset": "power",
        "pool": "default_pool",
        "tags": ["ml", "lgbm", "power", "batch"]
    },
]

# Factoryë¡œ DAG ìƒì„±
for config in TRAINING_CONFIGS:
    dag_id = config["dag_id"]
    globals()[dag_id] = create_ml_training_dag(**config)
```

**ì¥ì :**
- ì¤‘ì•™ ê´€ë¦¬, ì„¤ì • ì¼ê´€ì„±
- YAML/JSON ê¸°ë°˜ ìë™í™” ê°€ëŠ¥
- í…œí”Œë¦¿ ë³€ê²½ ì‹œ ëª¨ë“  DAG ì¼ê´„ ì—…ë°ì´íŠ¸

**ë‹¨ì :**
- ì´ˆì‹¬ì ì§„ì… ì¥ë²½
- ë””ë²„ê¹… ë³µì¡ (ë™ì  ìƒì„±)
- íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì²˜ë¦¬ ì–´ë ¤ì›€

---

## ğŸš¨ Tick Data íŠ¹ìˆ˜ ê³ ë ¤ì‚¬í•­

### **ì¤‘ìš”: Tick ë°ì´í„°ëŠ” Airflowë§Œìœ¼ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!**

í˜„ì—…ì—ì„œ ê¸ˆìœµ Tick ë°ì´í„° ì•„í‚¤í…ì²˜:

```
ì‹¤ì‹œê°„ ë°ì´í„° íë¦„:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Market Data â”‚ 
â”‚  (Tick ìŠ¤íŠ¸ë¦¼) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Kafka/Kinesis   â”‚ â† ì‹¤ì‹œê°„ ìˆ˜ì§‘
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flink/Spark     â”‚ â† ì‹¤ì‹œê°„ í”¼ì²˜ ìƒì„±
â”‚   Streaming     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature Store   â”‚ â† Redis/Feast
â”‚  (ì‹¤ì‹œê°„ í”¼ì²˜)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                     â”‚
       â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Real-time   â”‚      â”‚  Airflow   â”‚ â† ë°°ì¹˜ ì¬í•™ìŠµ
â”‚ Inference   â”‚      â”‚  (ì¼/ì£¼)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   MLflow   â”‚
                     â”‚ (Model Reg)â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Airflowì˜ ì—­í•  (Tick ë°ì´í„°)

**1. ë°°ì¹˜ ëª¨ë¸ ì¬í•™ìŠµ (ì£¼ê¸°ì )**
```python
# tick_model_dag.py
schedule_interval='0 2 * * 0'  # ë§¤ì£¼ ì¼ìš”ì¼ ìƒˆë²½ 2ì‹œ

tasks:
1. aggregate_weekly_features
2. prepare_training_data
3. train_model (MLflow)
4. backtest_model
5. register_to_production (ì¡°ê±´ë¶€)
```

**2. ì—­ì‚¬ì  ë°ì´í„° ë°±í•„**
```python
# ê³¼ê±° ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ
start_date = '2024-01-01'
end_date = '2024-12-31'
```

**3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ë°°ì¹˜)**
```python
# ì¼ì¼ í†µê³„ í”¼ì²˜ ìƒì„±
- ì¼ì¤‘ ë³€ë™ì„±
- ê±°ë˜ëŸ‰ í”„ë¡œíŒŒì¼
- ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤
```

**ì‹¤ì‹œê°„ ì¶”ë¡ ì€ Airflow ì™¸ë¶€**:
- FastAPI/Flask + Model Server
- Feature Storeì—ì„œ ì‹¤ì‹œê°„ í”¼ì²˜ ì¡°íšŒ
- MLflowì—ì„œ ë¡œë“œí•œ ëª¨ë¸ ì‚¬ìš©

---

## ğŸ“ ê° DAG êµ¬ì¡° í…œí”Œë¦¿

### MNIST CNN DAG
```python
# dags/ml_mnist_cnn_dag.py
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import mlflow

default_args = {
    'owner': 'vision-team',
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'mnist_cnn_training',
    default_args=default_args,
    description='MNIST CNN Model Training with MLflow',
    schedule_interval=None,  # ìˆ˜ë™ íŠ¸ë¦¬ê±°
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=['ml', 'cnn', 'mnist', 'experiment'],
)

def prepare_mnist_data(**context):
    """MNIST ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    from tensorflow.keras.datasets import mnist
    import numpy as np
    
    mlflow.set_tracking_uri("http://mlflow:5000")
    mlflow.set_experiment("mnist-cnn-experiments")
    
    with mlflow.start_run(run_name="prepare_data"):
        (x_train, y_train), (x_test, y_test) = mnist.load_data()
        
        # ì •ê·œí™”
        x_train = x_train.astype('float32') / 255.0
        x_test = x_test.astype('float32') / 255.0
        
        mlflow.log_param("train_samples", len(x_train))
        mlflow.log_param("test_samples", len(x_test))
        
        # ë°ì´í„° ì €ì¥ (S3/SeaweedFS)
        return {"data_path": "s3://lakehouse/mnist/data"}

def train_mnist_cnn(**context):
    """CNN ëª¨ë¸ í•™ìŠµ"""
    import tensorflow as tf
    
    mlflow.set_tracking_uri("http://mlflow:5000")
    mlflow.set_experiment("mnist-cnn-experiments")
    
    with mlflow.start_run(run_name="train_cnn"):
        # ëª¨ë¸ ì •ì˜
        model = tf.keras.Sequential([
            tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),
            tf.keras.layers.MaxPooling2D((2,2)),
            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
            tf.keras.layers.MaxPooling2D((2,2)),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(10, activation='softmax')
        ])
        
        model.compile(optimizer='adam',
                     loss='sparse_categorical_crossentropy',
                     metrics=['accuracy'])
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…
        mlflow.log_param("optimizer", "adam")
        mlflow.log_param("epochs", 10)
        mlflow.log_param("batch_size", 32)
        
        # í•™ìŠµ (ì‹¤ì œë¡œëŠ” ë°ì´í„° ë¡œë“œ)
        # history = model.fit(x_train, y_train, epochs=10, validation_split=0.2)
        
        # ë©”íŠ¸ë¦­ ë¡œê¹…
        mlflow.log_metric("train_accuracy", 0.98)
        mlflow.log_metric("val_accuracy", 0.97)
        
        # ëª¨ë¸ ì €ì¥
        mlflow.tensorflow.log_model(model, "model")
        
        return {"model_uri": mlflow.get_artifact_uri("model")}

def evaluate_mnist_model(**context):
    """ëª¨ë¸ í‰ê°€"""
    mlflow.set_tracking_uri("http://mlflow:5000")
    
    with mlflow.start_run(run_name="evaluate"):
        # í‰ê°€ ë¡œì§
        test_accuracy = 0.97
        mlflow.log_metric("test_accuracy", test_accuracy)
        
        return {"test_accuracy": test_accuracy}

def register_mnist_model(**context):
    """MLflow Model Registryì— ë“±ë¡"""
    ti = context['ti']
    test_accuracy = ti.xcom_pull(task_ids='evaluate_model')['test_accuracy']
    
    if test_accuracy > 0.95:  # ì„ê³„ê°’
        mlflow.set_tracking_uri("http://mlflow:5000")
        
        model_uri = ti.xcom_pull(task_ids='train_model')['model_uri']
        
        mlflow.register_model(
            model_uri=model_uri,
            name="mnist-cnn-model"
        )
        
        print(f"âœ… Model registered with accuracy: {test_accuracy}")
    else:
        print(f"âŒ Model accuracy {test_accuracy} below threshold")

# Task ì •ì˜
task_prepare = PythonOperator(
    task_id='prepare_data',
    python_callable=prepare_mnist_data,
    dag=dag,
)

task_train = PythonOperator(
    task_id='train_model',
    python_callable=train_mnist_cnn,
    pool='gpu_pool',
    dag=dag,
)

task_evaluate = PythonOperator(
    task_id='evaluate_model',
    python_callable=evaluate_mnist_model,
    dag=dag,
)

task_register = PythonOperator(
    task_id='register_model',
    python_callable=register_mnist_model,
    dag=dag,
)

# Task ì˜ì¡´ì„±
task_prepare >> task_train >> task_evaluate >> task_register
```

### CIFAR-10 CNN DAG
```python
# dags/ml_cifar10_cnn_dag.py
# MNISTì™€ ìœ ì‚¬í•œ êµ¬ì¡°, ë°ì´í„°ì…‹ê³¼ ëª¨ë¸ ì•„í‚¤í…ì²˜ë§Œ ë³€ê²½

dag = DAG(
    'cifar10_cnn_training',
    default_args=default_args,
    description='CIFAR-10 CNN Model Training with MLflow',
    schedule_interval=None,
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=['ml', 'cnn', 'cifar10', 'experiment'],
)

# prepare_data, train_model, evaluate_model, register_model
# (êµ¬ì¡°ëŠ” MNISTì™€ ë™ì¼, ë°ì´í„° ë¡œë“œë§Œ ë³€ê²½)
```

### Tick Data Model DAG
```python
# dags/ml_tick_model_dag.py
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.sensors.external_task import ExternalTaskSensor
from datetime import datetime, timedelta

default_args = {
    'owner': 'quant-team',
    'retries': 3,
    'retry_delay': timedelta(minutes=2),
    'priority_weight': 10,  # ê°€ì¥ ë†’ì€ ìš°ì„ ìˆœìœ„
}

dag = DAG(
    'tick_model_training',
    default_args=default_args,
    description='Tick Data Model Training (Batch)',
    schedule_interval='0 2 * * 0',  # ë§¤ì£¼ ì¼ìš”ì¼ ìƒˆë²½ 2ì‹œ
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=['ml', 'tick', 'production', 'timeseries'],
)

def aggregate_tick_features(**context):
    """ì£¼ê°„ Tick ë°ì´í„° ì§‘ê³„"""
    from pyspark.sql import SparkSession
    import mlflow
    
    mlflow.set_tracking_uri("http://mlflow:5000")
    mlflow.set_experiment("tick-model-production")
    
    with mlflow.start_run(run_name="aggregate_features"):
        spark = SparkSession.builder.appName("TickAggregation").getOrCreate()
        
        # Trino/Icebergì—ì„œ ë°ì´í„° ì½ê¸°
        df = spark.read.format("iceberg") \
            .load("lakehouse.silver.tick_data")
        
        # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
        # - ì‹œê°„ëŒ€ë³„ ë³€ë™ì„±
        # - ê±°ë˜ëŸ‰ í”„ë¡œíŒŒì¼
        # - ê°€ê²© ëª¨ë©˜í…€
        
        mlflow.log_metric("records_processed", df.count())
        
        return {"feature_path": "s3://lakehouse/tick/features/"}

def train_tick_model(**context):
    """ì‹œê³„ì—´ ëª¨ë¸ í•™ìŠµ"""
    from sklearn.ensemble import RandomForestRegressor
    import mlflow
    
    mlflow.set_tracking_uri("http://mlflow:5000")
    mlflow.set_experiment("tick-model-production")
    
    with mlflow.start_run(run_name="train_model"):
        # ë°ì´í„° ë¡œë“œ
        # X, y = load_features()
        
        model = RandomForestRegressor(n_estimators=100)
        # model.fit(X, y)
        
        mlflow.log_param("model_type", "RandomForest")
        mlflow.log_param("n_estimators", 100)
        
        mlflow.sklearn.log_model(model, "model")
        
        return {"model_uri": mlflow.get_artifact_uri("model")}

def backtest_tick_model(**context):
    """ë°±í…ŒìŠ¤íŒ…"""
    import mlflow
    
    mlflow.set_tracking_uri("http://mlflow:5000")
    
    with mlflow.start_run(run_name="backtest"):
        # ë°±í…ŒìŠ¤íŒ… ë¡œì§
        sharpe_ratio = 1.8
        max_drawdown = 0.15
        
        mlflow.log_metric("sharpe_ratio", sharpe_ratio)
        mlflow.log_metric("max_drawdown", max_drawdown)
        
        return {
            "sharpe_ratio": sharpe_ratio,
            "max_drawdown": max_drawdown
        }

def register_tick_model(**context):
    """í”„ë¡œë•ì…˜ ë“±ë¡ (ì¡°ê±´ë¶€)"""
    ti = context['ti']
    backtest_result = ti.xcom_pull(task_ids='backtest_model')
    
    if backtest_result['sharpe_ratio'] > 1.5:
        mlflow.set_tracking_uri("http://mlflow:5000")
        
        model_uri = ti.xcom_pull(task_ids='train_model')['model_uri']
        
        # í”„ë¡œë•ì…˜ìœ¼ë¡œ ìŠ¹ê²©
        client = mlflow.tracking.MlflowClient()
        model_version = client.create_model_version(
            name="tick-model",
            source=model_uri,
            run_id=mlflow.active_run().info.run_id
        )
        
        client.transition_model_version_stage(
            name="tick-model",
            version=model_version.version,
            stage="Production"
        )
        
        print(f"âœ… Model promoted to Production")
    else:
        print(f"âŒ Model did not meet production criteria")

# Task ì •ì˜
task_aggregate = PythonOperator(
    task_id='aggregate_features',
    python_callable=aggregate_tick_features,
    pool='high_priority_cpu',
    dag=dag,
)

task_train = PythonOperator(
    task_id='train_model',
    python_callable=train_tick_model,
    pool='high_priority_cpu',
    dag=dag,
)

task_backtest = PythonOperator(
    task_id='backtest_model',
    python_callable=backtest_tick_model,
    dag=dag,
)

task_register = PythonOperator(
    task_id='register_model',
    python_callable=register_tick_model,
    dag=dag,
)

# Task ì˜ì¡´ì„±
task_aggregate >> task_train >> task_backtest >> task_register
```

### ì „ë ¥ ë°ì´í„° LightGBM DAG
```python
# dags/ml_power_lgbm_dag.py
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta

default_args = {
    'owner': 'energy-team',
    'retries': 2,
    'retry_delay': timedelta(minutes=3),
}

dag = DAG(
    'power_lgbm_training',
    default_args=default_args,
    description='Power Consumption Forecasting with LightGBM',
    schedule_interval='0 1 * * *',  # ë§¤ì¼ ì˜¤ì „ 1ì‹œ
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=['ml', 'lgbm', 'power', 'forecasting'],
)

def prepare_power_data(**context):
    """ì „ë ¥ ë°ì´í„° ì¤€ë¹„"""
    import mlflow
    from pyspark.sql import SparkSession
    
    mlflow.set_tracking_uri("http://mlflow:5000")
    mlflow.set_experiment("power-consumption-forecasting")
    
    with mlflow.start_run(run_name="prepare_data"):
        spark = SparkSession.builder.appName("PowerData").getOrCreate()
        
        # ì–´ì œ ë°ì´í„° ë¡œë“œ
        execution_date = context['ds']
        df = spark.sql(f"""
            SELECT * FROM lakehouse.silver.power_consumption
            WHERE date = '{execution_date}'
        """)
        
        mlflow.log_param("execution_date", execution_date)
        mlflow.log_metric("records", df.count())
        
        return {"data_path": "s3://lakehouse/power/data/"}

def train_lgbm_model(**context):
    """LightGBM ëª¨ë¸ í•™ìŠµ"""
    import lightgbm as lgb
    import mlflow
    
    mlflow.set_tracking_uri("http://mlflow:5000")
    mlflow.set_experiment("power-consumption-forecasting")
    
    with mlflow.start_run(run_name="train_lgbm"):
        # ë°ì´í„° ë¡œë“œ
        # X_train, y_train = load_data()
        
        params = {
            'objective': 'regression',
            'metric': 'rmse',
            'num_leaves': 31,
            'learning_rate': 0.05,
            'feature_fraction': 0.9
        }
        
        # model = lgb.train(params, train_set)
        
        mlflow.log_params(params)
        mlflow.log_metric("train_rmse", 0.15)
        mlflow.log_metric("val_rmse", 0.18)
        
        # mlflow.lightgbm.log_model(model, "model")
        
        return {"model_uri": mlflow.get_artifact_uri("model")}

def evaluate_power_model(**context):
    """ëª¨ë¸ í‰ê°€"""
    import mlflow
    
    mlflow.set_tracking_uri("http://mlflow:5000")
    
    with mlflow.start_run(run_name="evaluate"):
        # í‰ê°€
        test_rmse = 0.17
        mae = 0.12
        
        mlflow.log_metric("test_rmse", test_rmse)
        mlflow.log_metric("mae", mae)
        
        return {"test_rmse": test_rmse, "mae": mae}

def register_power_model(**context):
    """ëª¨ë¸ ë“±ë¡"""
    ti = context['ti']
    metrics = ti.xcom_pull(task_ids='evaluate_model')
    
    if metrics['test_rmse'] < 0.20:  # ì„ê³„ê°’
        mlflow.set_tracking_uri("http://mlflow:5000")
        
        model_uri = ti.xcom_pull(task_ids='train_model')['model_uri']
        
        mlflow.register_model(
            model_uri=model_uri,
            name="power-consumption-model"
        )
        
        print(f"âœ… Model registered with RMSE: {metrics['test_rmse']}")
    else:
        print(f"âŒ Model RMSE {metrics['test_rmse']} above threshold")

# Task ì •ì˜
task_prepare = PythonOperator(
    task_id='prepare_data',
    python_callable=prepare_power_data,
    dag=dag,
)

task_train = PythonOperator(
    task_id='train_model',
    python_callable=train_lgbm_model,
    dag=dag,
)

task_evaluate = PythonOperator(
    task_id='evaluate_model',
    python_callable=evaluate_power_model,
    dag=dag,
)

task_register = PythonOperator(
    task_id='register_model',
    python_callable=register_power_model,
    dag=dag,
)

# Task ì˜ì¡´ì„±
task_prepare >> task_train >> task_evaluate >> task_register
```

---

## ğŸ”§ ê³µí†µ ëª¨ë“ˆ êµ¬ì¡°

### common/mlflow_utils.py
```python
"""MLflow ê³µí†µ ìœ í‹¸ë¦¬í‹°"""
import mlflow
import os

MLFLOW_TRACKING_URI = os.getenv('MLFLOW_TRACKING_URI', 'http://mlflow:5000')

def init_mlflow(experiment_name: str):
    """MLflow ì´ˆê¸°í™”"""
    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
    mlflow.set_experiment(experiment_name)

def log_dataset_info(dataset_name: str, num_samples: int, num_features: int):
    """ë°ì´í„°ì…‹ ì •ë³´ ë¡œê¹…"""
    mlflow.log_param("dataset", dataset_name)
    mlflow.log_param("num_samples", num_samples)
    mlflow.log_param("num_features", num_features)

def register_model_if_better(model_uri: str, model_name: str, 
                              metric_name: str, metric_value: float, 
                              threshold: float):
    """ì¡°ê±´ë¶€ ëª¨ë¸ ë“±ë¡"""
    if metric_value > threshold:
        mlflow.register_model(model_uri=model_uri, name=model_name)
        return True
    return False
```

### common/config.py
```python
"""ê³µí†µ ì„¤ì •"""

# MLflow ì„¤ì •
MLFLOW_CONFIG = {
    'tracking_uri': 'http://mlflow:5000',
    'artifact_location': 's3://lakehouse/mlflow/artifacts',
}

# Airflow Pool ì„¤ì •
AIRFLOW_POOLS = {
    'gpu_pool': {'slots': 2, 'description': 'GPU tasks'},
    'high_priority_cpu': {'slots': 4, 'description': 'High priority CPU'},
    'default_pool': {'slots': 8, 'description': 'Default pool'},
}

# ëª¨ë¸ë³„ ì„ê³„ê°’
MODEL_THRESHOLDS = {
    'mnist': {'accuracy': 0.95},
    'cifar10': {'accuracy': 0.85},
    'tick': {'sharpe_ratio': 1.5, 'max_drawdown': 0.20},
    'power': {'rmse': 0.20},
}
```

---

## ğŸ¨ DAG Factory íŒ¨í„´ (ê³ ê¸‰)

### dags/model_training_factory.py
```python
"""ëª¨ë¸ í•™ìŠµ DAG Factory"""
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
from typing import Dict, Any
import mlflow

def create_ml_training_dag(
    dag_id: str,
    schedule: str,
    model_type: str,
    dataset: str,
    framework: str,
    pool: str = 'default_pool',
    priority_weight: int = 5,
    tags: list = None
) -> DAG:
    """ML í•™ìŠµ DAG ìƒì„± Factory"""
    
    default_args = {
        'owner': 'ml-team',
        'retries': 2,
        'retry_delay': timedelta(minutes=3),
        'priority_weight': priority_weight,
    }
    
    dag = DAG(
        dag_id=dag_id,
        default_args=default_args,
        description=f'{dataset.upper()} Model Training with {framework}',
        schedule_interval=schedule,
        start_date=datetime(2025, 1, 1),
        catchup=False,
        tags=tags or ['ml', model_type, dataset],
    )
    
    # ë™ì  Task ìƒì„±
    def prepare_data(**context):
        mlflow.set_tracking_uri("http://mlflow:5000")
        mlflow.set_experiment(f"{dataset}-{model_type}")
        
        with mlflow.start_run(run_name="prepare_data"):
            # ë°ì´í„° ì¤€ë¹„ ë¡œì§
            print(f"Preparing {dataset} data...")
            mlflow.log_param("dataset", dataset)
            return {"status": "success"}
    
    def train_model(**context):
        mlflow.set_tracking_uri("http://mlflow:5000")
        
        with mlflow.start_run(run_name="train_model"):
            print(f"Training {model_type} on {dataset} using {framework}...")
            mlflow.log_param("framework", framework)
            mlflow.log_param("model_type", model_type)
            return {"model_uri": "s3://models/"}
    
    def evaluate_model(**context):
        mlflow.set_tracking_uri("http://mlflow:5000")
        
        with mlflow.start_run(run_name="evaluate"):
            print(f"Evaluating {model_type} model...")
            mlflow.log_metric("accuracy", 0.95)
            return {"accuracy": 0.95}
    
    def register_model(**context):
        print(f"Registering {dataset} model to MLflow...")
        return {"status": "registered"}
    
    # Task ìƒì„±
    task_prepare = PythonOperator(
        task_id='prepare_data',
        python_callable=prepare_data,
        dag=dag,
    )
    
    task_train = PythonOperator(
        task_id='train_model',
        python_callable=train_model,
        pool=pool,
        dag=dag,
    )
    
    task_evaluate = PythonOperator(
        task_id='evaluate_model',
        python_callable=evaluate_model,
        dag=dag,
    )
    
    task_register = PythonOperator(
        task_id='register_model',
        python_callable=register_model,
        dag=dag,
    )
    
    # Task ì˜ì¡´ì„±
    task_prepare >> task_train >> task_evaluate >> task_register
    
    return dag


# DAG ì„¤ì •
TRAINING_CONFIGS = [
    {
        "dag_id": "mnist_cnn_training",
        "schedule": None,
        "model_type": "cnn",
        "framework": "tensorflow",
        "dataset": "mnist",
        "pool": "gpu_pool",
        "tags": ["ml", "cnn", "mnist", "experiment"]
    },
    {
        "dag_id": "cifar10_cnn_training",
        "schedule": None,
        "model_type": "cnn",
        "framework": "pytorch",
        "dataset": "cifar10",
        "pool": "gpu_pool",
        "tags": ["ml", "cnn", "cifar10", "experiment"]
    },
    {
        "dag_id": "tick_model_training",
        "schedule": "0 2 * * 0",
        "model_type": "timeseries",
        "framework": "sklearn",
        "dataset": "tick",
        "pool": "high_priority_cpu",
        "priority_weight": 10,
        "tags": ["ml", "tick", "production"]
    },
    {
        "dag_id": "power_lgbm_training",
        "schedule": "0 1 * * *",
        "model_type": "gbm",
        "framework": "lightgbm",
        "dataset": "power",
        "pool": "default_pool",
        "tags": ["ml", "lgbm", "power"]
    },
]

# Factoryë¡œ DAG ìƒì„±
for config in TRAINING_CONFIGS:
    dag_id = config.pop("dag_id")
    globals()[dag_id] = create_ml_training_dag(dag_id=dag_id, **config)
```

---

## ğŸš€ ë°°í¬ ë° ìš´ì˜ ì „ëµ

### Phase 1: ì´ˆê¸° êµ¬í˜„ (1-2ì£¼)
```
1. 4ê°œ DAG íŒŒì¼ ìƒì„± (ì§ê´€ì  ì ‘ê·¼)
2. ê³µí†µ ëª¨ë“ˆ ë¶„ë¦¬ (mlflow_utils, config)
3. ê° DAG ë…ë¦½ í…ŒìŠ¤íŠ¸
```

### Phase 2: í†µí•© ë° ìµœì í™” (2-3ì£¼)
```
1. MLflow Experiment ì—°ë™ í™•ì¸
2. Airflow Pool/Queue ì„¤ì •
3. SLA ë° ì•Œë¦¼ êµ¬ì„±
```

### Phase 3: í”„ë¡œë•ì…˜ (4ì£¼~)
```
1. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ (Grafana)
2. ìë™ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸
3. A/B í…ŒìŠ¤íŠ¸ ì¸í”„ë¼
```

### Phase 4: ê³ ë„í™” (ì„ íƒ)
```
1. Factory íŒ¨í„´ìœ¼ë¡œ ë¦¬íŒ©í† ë§
2. YAML ê¸°ë°˜ ì„¤ì • ê´€ë¦¬
3. CI/CD íŒŒì´í”„ë¼ì¸ í†µí•©
```

---

## ğŸ“Š í˜„ì—… ì²´í¬ë¦¬ìŠ¤íŠ¸

### âœ… DAG ì„¤ê³„ ì›ì¹™
- [ ] ê° DAGëŠ” í•˜ë‚˜ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì›Œí¬í”Œë¡œìš°ë¥¼ ë‹´ë‹¹
- [ ] ìŠ¤ì¼€ì¤„ì´ ë‹¤ë¥´ë©´ ë¬´ì¡°ê±´ ë¶„ë¦¬
- [ ] ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ì´ ë‹¤ë¥´ë©´ ë¶„ë¦¬
- [ ] Ownershipì´ ë‹¤ë¥´ë©´ ë¶„ë¦¬
- [ ] ì¬ì²˜ë¦¬(Backfill) ë‹¨ìœ„ê°€ ë‹¤ë¥´ë©´ ë¶„ë¦¬

### âœ… MLflow í†µí•©
- [ ] ê° DAGëŠ” ë…ë¦½ì ì¸ Experiment ì‚¬ìš©
- [ ] Run nameì€ ëª…í™•í•˜ê²Œ (prepare_data, train_model ë“±)
- [ ] í•˜ì´í¼íŒŒë¼ë¯¸í„° ëª¨ë‘ log_paramìœ¼ë¡œ ê¸°ë¡
- [ ] ì£¼ìš” ë©”íŠ¸ë¦­ log_metricìœ¼ë¡œ ì¶”ì 
- [ ] ëª¨ë¸ì€ log_modelë¡œ ì €ì¥ (artifacts)
- [ ] ì¡°ê±´ë¶€ Model Registry ë“±ë¡

### âœ… ìš´ì˜ ê³ ë ¤ì‚¬í•­
- [ ] ê° DAGì˜ SLA ì •ì˜
- [ ] ì•Œë¦¼ ì±„ë„ ì„¤ì • (Slack/Email)
- [ ] ì¬ì‹œë„ ì •ì±… ì •ì˜
- [ ] Pool/Queue ë¦¬ì†ŒìŠ¤ í• ë‹¹
- [ ] ë¡œê·¸ ë³´ê´€ ì •ì±…

---

## ğŸ’¡ ê¶Œì¥ì‚¬í•­

### ë‹¹ì‹ ì˜ í”„ë¡œì íŠ¸ (lakehouse-tick)

1. **ì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥í•œ ì ‘ê·¼**:
   ```
   dags/
   â”œâ”€â”€ ml_mnist_cnn_dag.py        # ì‹œì‘
   â”œâ”€â”€ ml_cifar10_cnn_dag.py      # ë‹¤ìŒ
   â”œâ”€â”€ ml_tick_model_dag.py       # í•µì‹¬
   â”œâ”€â”€ ml_power_lgbm_dag.py       # ì¶”ê°€
   â””â”€â”€ common/
       â”œâ”€â”€ mlflow_utils.py
       â””â”€â”€ config.py
   ```

2. **ìš°ì„ ìˆœìœ„**:
   - 1ìˆœìœ„: Tick Model DAG (ë¹„ì¦ˆë‹ˆìŠ¤ í•µì‹¬)
   - 2ìˆœìœ„: Power LightGBM DAG (ì‹¤ìš©ì„±)
   - 3ìˆœìœ„: MNIST/CIFAR-10 (ì‹¤í—˜/í•™ìŠµ)

3. **í˜„ì¬ ml_pipeline_dag.py í™œìš©**:
   - í…œí”Œë¦¿ìœ¼ë¡œ ì‚¬ìš©
   - 4ê°œë¡œ ë³µì œ í›„ ê°ê° ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆ

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Airflow Best Practices](https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html)
- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)
- [MLflow Model Registry](https://mlflow.org/docs/latest/model-registry.html)

### í˜„ì—… ì‚¬ë¡€
- Uber: Michelangelo Platform (DAG per Model)
- Netflix: Metaflow (Workflow Orchestration)
- Airbnb: Bighead ML Platform (Airflow + MLflow)

### ì•„í‚¤í…ì²˜ íŒ¨í„´
- Lambda Architecture (ë°°ì¹˜ + ì‹¤ì‹œê°„)
- Kappa Architecture (ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì‹¬)
- Feature Store Pattern (Feast, Tecton)

---

## ğŸ¯ ë‹¤ìŒ ì•¡ì…˜

ì´ì œ ë‹¤ìŒ ì¤‘ ì„ íƒí•´ì£¼ì„¸ìš”:

1. **A) 4ê°œ DAG íŒŒì¼ ìƒì„±** (ì§ê´€ì , ê¶Œì¥)
   - ê°ê° ë…ë¦½ íŒŒì¼ë¡œ ìƒì„±
   - ê³µí†µ ëª¨ë“ˆ ë¶„ë¦¬
   - ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ

2. **B) Factory íŒ¨í„´ êµ¬í˜„** (ê³ ê¸‰)
   - 1ê°œ íŒŒì¼ì—ì„œ 4ê°œ DAG ìƒì„±
   - ì„¤ì • ê¸°ë°˜ ìë™í™”
   - í™•ì¥ì„± ë†’ìŒ

3. **C) í˜„ì¬ ml_pipeline_dag.py ë¦¬íŒ©í† ë§**
   - ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš©
   - 4ê°œë¡œ ë¶„ë¦¬
   - ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜

ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?

---

**ì‘ì„±ì¼**: 2025-12-28  
**ì‘ì„±ì**: Claude Sonnet 4.5 (MLflow/Airflow ì „ë¬¸ê°€ ëª¨ë“œ)  
**ë²„ì „**: 2.0
